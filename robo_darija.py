import openai
import pyttsx3
import sounddevice as sd
import numpy as np
import wavio

# ğŸ”‘ Ø¶Ø¹ Ù‡Ù†Ø§ API KEY Ø¯ÙŠØ§Ù„Ùƒ
openai.api_key = "YOUR_OPENAI_API_KEY"

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙˆØª
engine = pyttsx3.init()
engine.setProperty('rate', 150)  # Ø³Ø±Ø¹Ø© Ø§Ù„ÙƒÙ„Ø§Ù…
engine.setProperty('volume', 1.0)

# ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª
def record_audio(duration=5, fs=44100):
    print("Ø³Ø¬Ù‘Ù„ ÙƒÙ„Ø§Ù…Ùƒ Ø¯Ø§Ø¨Ø§...")
    recording = sd.rec(int(duration * fs), samplerate=fs, channels=1)
    sd.wait()
    wavio.write("input.wav", recording, fs, sampwidth=2)
    print("ØªÙ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ âœ…")
    return "input.wav"

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ (STT) Ø¨Ø§Ø³ØªØ¹Ù…Ø§Ù„ Whisper
def transcribe_audio(file_path):
    with open(file_path, "rb") as f:
        transcript = openai.audio.transcriptions.create(
            model="whisper-1",
            file=f
        )
    return transcript.text

# Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù†Øµ Ù„ OpenAI ChatGPT ÙˆØ§Ù„Ø±Ø¯
def ask_openai(prompt):
    response = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message["content"]

# Ø§Ù„ØªØ­Ø¯Ø« Ø¨Ø§Ù„ØµÙˆØª
def speak(text):
    engine.say(text)
    engine.runAndWait()

# ğŸ” Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
if __name__ == "__main__":
    while True:
        audio_file = record_audio(duration=5)  # Ø³Ø¬Ù„ 5 Ø«ÙˆØ§Ù†ÙŠ
        text = transcribe_audio(audio_file)
        print("Ø§Ù†Øª Ù‚Ù„Øª:", text)
        reply = ask_openai(text + " Ø¨Ø§Ù„Ø¯Ø§Ø±Ø¬Ø© Ø§Ù„Ù…ØºØ±Ø¨ÙŠØ©")
        print("Ø±ÙˆØ¨ÙˆØª:", reply)
        speak(reply)
